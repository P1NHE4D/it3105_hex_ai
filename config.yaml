agent:
  episodes: 50
  num_sim: 200
  save_interval: 10
  rbuf_size: 100
  default_policy: "agent"
  dynamic_sim: true
  epsilon: 0
  epsilon_decay: 0.99
  anet:
    # NOTE: when we start getting serious about training agents we should clearly separate between different games &
    # configurations.. For now just dump them to the default folder. Comment is here to show how I would dump weights
    # for a size 4 hex game
    #file_path: "hex_4"
    learning_rate: 0.01
    epochs: 1
    batch_size: 10
    optimizer: "adam"
    hidden_layers: [
      [32, "relu"],
    ]
  mcts:
    c: 1
    exp_prob: 1.0
game:
  name: "hex"
  params:
    board_size: 3
topp:
  include_uniform: true
  num_games_per_series: 50